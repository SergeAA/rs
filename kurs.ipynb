{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Курсовой проект"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Основное**\n",
    "- Дедлайн - 21 июня 23:59\n",
    "- Целевая метрика precision@5. Порог для уcпешной сдачи проекта precision@5 > 25%\n",
    "- Бейзлайн решения - [MainRecommender](https://github.com/geangohn/recsys-tutorial/blob/master/src/recommenders.py)\n",
    "- Сдаем ссылку на github с решением. На github должен быть файл recommendations.csv (user_id | [rec_1, rec_2, ...] с рекомендациями. rec_i - реальные id item-ов (из retail_train.csv)\n",
    "\n",
    "- Будет public тестовый датасет, на котором вы сможете измерять метрику\n",
    "- Также будет private тестовый датасет для измерения финального качества\n",
    "- НЕ обязательно, но крайне желательно использовать 2-ух уровневые рекоммендательные системы в проекте\n",
    "\n",
    "**Hints:** \n",
    "\n",
    "Сначала просто попробуйте разные параметры MainRecommender:  \n",
    "- N в топ-N товарах при формировании user-item матирцы (сейчас топ-5000)  \n",
    "- Различные веса в user-item матрице (0/1, кол-во покупок, log(кол-во покупок + 1), сумма покупки, ...)  \n",
    "- Разные взвешивания матрицы (TF-IDF, BM25 - у него есть параметры)  \n",
    "- Разные смешивания рекомендаций (обратите внимание на бейзлайн - прошлые покупки юзера)  \n",
    "\n",
    "Сделайте MVP - минимально рабочий продукт - (пусть даже top-popular), а потом его улучшайте\n",
    "\n",
    "Если вы делаете двухуровневую модель - следите за валидацией "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Библиотеки и загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T10:48:46.213614Z",
     "start_time": "2020-06-21T10:48:40.391905Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/xander/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join(os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.metrics import total_precision_at_N\n",
    "from src.utils import prefilter_items, split_train_val, prepare_users, prepare_items, unstack_user_item\n",
    "from src.recommenders import RecommenderDataset, BaseRecommender, OwnRecommender, AlsRecommender, Level2Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T10:48:55.102985Z",
     "start_time": "2020-06-21T10:48:46.223424Z"
    }
   },
   "outputs": [],
   "source": [
    "DATAROOT = './data/'\n",
    "\n",
    "data = pd.read_csv(f'{DATAROOT}transactions.csv.gz', compression='gzip')\n",
    "test = pd.read_csv(f'{DATAROOT}test.csv.gz', compression='gzip')\n",
    "\n",
    "items = pd.read_csv(f'{DATAROOT}product.csv.gz')\n",
    "items.columns = [col.lower() for col in items.columns]\n",
    "items.rename(columns={'product_id': 'item_id'}, inplace=True)\n",
    "items = prepare_items(items)\n",
    "\n",
    "users = pd.read_csv(f'{DATAROOT}demographic.csv.gz')\n",
    "users.columns = [col.lower() for col in users.columns]\n",
    "users.rename(columns={'household_key': 'user_id'}, inplace=True)\n",
    "users = prepare_users(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разбивка и обучение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T10:48:59.828280Z",
     "start_time": "2020-06-21T10:48:55.107840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decreased amount of items from 83685 to 5001\n"
     ]
    }
   ],
   "source": [
    "# делим на train / validate1 / validate2\n",
    "train, val1, val2 = split_train_val(data, 6, 3)\n",
    "\n",
    "# фильтруем items от ненужного и берем только 5000 (+1 на остальное)\n",
    "was = train.item_id.nunique()\n",
    "train = prefilter_items(train, price=(1, 100), popular=(0.001, 0.5), products=items, top_n=5000)\n",
    "print(f'Decreased amount of items from {was} to {train.item_id.nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расчет моделей первого уровня"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T10:51:33.110114Z",
     "start_time": "2020-06-21T10:48:59.831695Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e04ecae285144f99409c80576949230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5001.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "242200ba5c2b4768a5239d7e7e1f629d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Оценка TRAIN\n",
      "Оценка VALID\n",
      "Оценка TEST\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>valid</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision_base</th>\n",
       "      <td>0.985829</td>\n",
       "      <td>0.371309</td>\n",
       "      <td>0.282334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_als_similar_users</th>\n",
       "      <td>0.475661</td>\n",
       "      <td>0.173538</td>\n",
       "      <td>0.135915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_als_similar_items</th>\n",
       "      <td>0.376781</td>\n",
       "      <td>0.083565</td>\n",
       "      <td>0.063554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_als</th>\n",
       "      <td>0.250440</td>\n",
       "      <td>0.052089</td>\n",
       "      <td>0.038515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_own</th>\n",
       "      <td>0.041233</td>\n",
       "      <td>0.006128</td>\n",
       "      <td>0.004881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                train     valid      test\n",
       "precision_base               0.985829  0.371309  0.282334\n",
       "precision_als_similar_users  0.475661  0.173538  0.135915\n",
       "precision_als_similar_items  0.376781  0.083565  0.063554\n",
       "precision_als                0.250440  0.052089  0.038515\n",
       "precision_own                0.041233  0.006128  0.004881"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!export MKL_NUM_THREADS=1\n",
    "\n",
    "ds = RecommenderDataset(train)\n",
    "\n",
    "base = BaseRecommender(ds).fit()\n",
    "own = OwnRecommender(ds).fit()\n",
    "als = AlsRecommender(ds).fit()\n",
    "\n",
    "def recommend(data, N=50):\n",
    "    res = data.groupby('user_id')['item_id'].unique().reset_index()\n",
    "    res.columns=['user_id', 'actual']\n",
    "\n",
    "    res['recommend_base'] = base.recommend(res.user_id, N)\n",
    "    res['recommend_own'] = own.recommend(res.user_id, N)\n",
    "    res['recommend_als'] = als.recommend(res.user_id, N)\n",
    "    res['recommend_als_similar_users'] = als.recommend(res.user_id, N, by='similarUsers')\n",
    "    res['recommend_als_similar_items'] = als.recommend(res.user_id, N, by='similarItems')\n",
    "    return res\n",
    "\n",
    "result = pd.DataFrame(columns=['train', 'valid', 'test'])\n",
    "\n",
    "print('Оценка TRAIN')\n",
    "result['train'] = total_precision_at_N(recommend(train, 5), 5)\n",
    "\n",
    "print('Оценка VALID')\n",
    "val1_candidates = recommend(val1)\n",
    "val2_candidates = recommend(val2)\n",
    "result['valid'] = total_precision_at_N(val1_candidates, 5)\n",
    "\n",
    "print('Оценка TEST')\n",
    "test_candidates = recommend(test)\n",
    "result['test'] = total_precision_at_N(test_candidates, 5)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расчет моделей второго уровня"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T10:51:54.108284Z",
     "start_time": "2020-06-21T10:51:33.113025Z"
    }
   },
   "outputs": [],
   "source": [
    "# подготовим dataframes с кандидатами\n",
    "model1_candidates = 'recommend_als'\n",
    "\n",
    "train_lv2 = unstack_user_item(val1_candidates, model1_candidates, 'actual')\n",
    "valid_lv2 = unstack_user_item(val2_candidates, model1_candidates, 'actual')\n",
    "test_lv2  = unstack_user_item(test_candidates, model1_candidates, 'actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-21T10:48:40.595Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ..."
     ]
    }
   ],
   "source": [
    "# Обучаем на кандидатах для VAL-1\n",
    "Level2 = Level2Recommender(transactions=data, \n",
    "                           items=items, items_emb=als.items_embedings(),\n",
    "                           users=users, users_emb=als.users_embedings())\n",
    "\n",
    "Level2.fit_predict_report(train_lv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-21T10:48:40.598Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def recommend(data, candidates, N=5):\n",
    "    df = Level2.recommend(data, N)\n",
    "    tmp = candidates.merge(df, how='left', on='user_id')\n",
    "    return tmp[['user_id', 'actual', 'recommend_level2']]\n",
    "\n",
    "result2 = pd.DataFrame(columns=['train', 'valid', 'test'])\n",
    "\n",
    "print('Оценка TRAIN (для этого уровня это VAL-1)')\n",
    "result2['train'] = total_precision_at_N(recommend(train_lv2, val1_candidates))\n",
    "\n",
    "print('Оценка VALID (для этого уровня это VAL-2)')\n",
    "result2['valid'] = total_precision_at_N(recommend(valid_lv2, val2_candidates))\n",
    "\n",
    "print('Оценка TEST')\n",
    "result2['test'] = total_precision_at_N(recommend(test_lv2, test_candidates))\n",
    "\n",
    "pd.concat([result, result2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вывод\n",
    "\n",
    "> **Как я не пытался у меня не получилось лучшего качества чем я получил на модели первого уровня когда я просто рекомендую популярные или те которые пользователь до этого покупал**\n",
    "\n",
    "> Модель второго уровня почти всегда только усугубляет ситуацию, видимо я что-то всеже упускаю из виду"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итоговая модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-21T10:48:40.710Z"
    }
   },
   "outputs": [],
   "source": [
    "# кандидаты\n",
    "\n",
    "def level1(data):\n",
    "    df = data[['user_id', 'item_id']].drop_duplicates()\n",
    "    df = df.groupby('user_id')['item_id'].unique().reset_index()\n",
    "    df.columns=['user_id', 'actual']\n",
    "    df['recommend_main'] = base.recommend(df.user_id, 50)\n",
    "    print('\\n >> Level1 Precision@5:')\n",
    "    print(total_precision_at_N(df))\n",
    "    lv2 = unstack_user_item(df, 'recommend_main', 'actual')\n",
    "    return df, lv2\n",
    "\n",
    "def level2(data, candidates):\n",
    "    tmp = Level2.recommend(data, 5)\n",
    "    tmp = candidates.merge(tmp, how='left', on='user_id')\n",
    "    print('\\n >> Level2 Precision@5:\\n')\n",
    "    print(total_precision_at_N(tmp))\n",
    "    return tmp\n",
    "    \n",
    "def model(data, fit=False):\n",
    "    candidates, lv2 = level1(data)\n",
    "    if fit:\n",
    "        Level2.fit_predict_report(lv2)\n",
    "    return level2(lv2, candidates)\n",
    "\n",
    "print('\\n---- Качество на TRAIN-e ----')\n",
    "main = model(data, True)\n",
    "\n",
    "print('\\n---- Качество на TEST-e ----')\n",
    "_ = model(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохранение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-21T10:48:40.783Z"
    }
   },
   "outputs": [],
   "source": [
    "def save(data, field, file):\n",
    "    tmp = data[['user_id', field]].copy()\n",
    "    tmp.columns = ['user_id', 'result']\n",
    "    tmp['result'] = tmp.result.apply(lambda x: list(x)[:5])\n",
    "    tmp.to_csv(f'{file}.csv')\n",
    "    tmp.to_pickle(f'{file}.pkl')\n",
    "\n",
    "    \n",
    "# сохраним предсазания модели первого уровня\n",
    "save(main, 'recommend_main', 'level1')\n",
    "\n",
    "# сохраним предсазания модели второго уровня\n",
    "save(main, 'recommend_level2', 'recommendations')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
